import os
import json
import itertools as it
from mtsv.utils import script_path, get_database_params
from glob import glob
from mtsv.parsing import parse_output_row, file_type, parse_query_id
from Bio import SeqIO
SCRIPT = script_path('MTSv_extract.py')
REPORT = "extract_report.html"

MEM=30


if "database_config" not in config:
    config['database_config'] = json.loads(open(os.path.join(
        os.path.basename(config['merge_file']),
        ".params"),
        'r').read())['merge_file'][config['merge_file']]['database_config']

config['taxdump_path'] = file_type(get_database_params(
    config['database_config'], 'taxdump-path'))

if config['by_sample']:
    # get number of samples
    with open(config['merge_file'], 'r') as infile:
        n_samples = len(
            parse_output_row(
                infile.readline()).counts)
    OUTPUT = [os.path.join(
        config['extract_path'],
        "{0}_{1}.fasta".format(tax, n))
              for tax, n in it.product(
                  config['taxids'],
                  range(1, n_samples + 1))]

else:
    OUTPUT = [os.path.join(config['extract_path'], str(tax) + ".fasta") 
    for tax in config['taxids']]


FASTA = file_type(json.loads(
    open(os.path.join(
        os.path.dirname(
            config['merge_file']),
        ".params"), 'r').read())['merge_file'][config['merge_file']]['fasta'])   


rule all:
    input:
        REPORT

rule extract_report:
    input: OUTPUT
    output:
        REPORT
    params:
        path=config['extract_path']
    run:
        from snakemake.utils import report
        print("INPUT", input)
        total_queries = [len(list(SeqIO.parse(fasta, "fasta"))) for fasta in input]
        _files = [os.path.basename(out) for out in OUTPUT]
        data = "\n".join(["{0:<23} {1:<11}".format(f, q) for f, q in zip(_files, total_queries)])
        report(
            """ 
            Extract Report
            ============================
            **Extracted taxa fasta files are reported in:**\n
            {params.path}\n
            Number of unique queries per file:\n
            =========================  ============
            File                       No. Queries
            =========================  ============
            {data}
            =========================  ============

            """, output[0])



rule extract:
    """Get query sequences associated with a given taxid"""
    output: OUTPUT           
    input: 
        fasta=FASTA,
        clp=config['merge_file']
    resources:
        mem_mb=lambda wildcards, attempt: attempt * MEM
    params:
        taxdump=config['taxdump_path'],
        taxids=config['taxids'],
        outpath=config['extract_path'],
        descendants=config['descendants'],
        by_sample=config['by_sample']
    threads:
        config['threads']
    log:
        config['log_file']
    message:
        """Extracting query sequences from {input.fasta} for taxids: {params.taxids}
        Writing to {output}"""
    script: SCRIPT
