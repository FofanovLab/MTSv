import os
import json
import itertools as it
from mtsv.utils import script_path
from mtsv.parsing import parse_output_row, file_type, parse_query_id
from Bio import SeqIO
SCRIPT = script_path('MTSv_extract.py')
REPORT = "extract_report.html"

MEM=30
if config['by_sample']:
    # get number of samples
    with open(config['merge_file'], 'r') as infile:
        n_samples = len(
            parse_output_row(
                infile.readline()).counts)
    OUTPUT = [os.path.join(
        config['extract_path'],
        "{0}_{1}.fasta".format(tax, n))
              for tax, n in it.product(
                  taxids, range(1, n_samples + 1))]

else:
    OUTPUT = [os.path.join(config['extract_path'], tax + ".fasta") 
    for tax in config['taxids']]

[open(f, 'a').close() for f in OUTPUT]

FASTA = file_type(json.load(
    open(os.path.join(
        os.path.dirname(
            config['merge_file']),
        ".params"), 'r').read())['merge_file'][config['merge_file']]['fasta'])    

rule all:
    input:
        REPORT

rule extract_report:
    input:
        OUTPUT
    output:
        REPORT
    params:
        path=config['extract_path']
    run:
        from snakemake.utils import report
        total_queries = [len(list(SeqIO.parse(fasta, "fasta"))) for fasta in input[0]]
        _files = [os.path.basename(out) for out in OUTPUT]
        data = zip(_files, total_queries)  
        report(
            """ 
            Extract Report
            ============================
            **Extracted taxa fasta files are reported in:**\n
            {params.extract_path}\n
            Number of unique queries per file:\n
            =========================  ============
            File                       No. Queries
            =========================  ============
            {data}
            =========================  ============

            """, output[0])



rule extract:
    """Get query sequences associated with a given taxid"""
    output: OUTPUT           
    input: 
        fasta=FASTA,
        clp=config['merge_file']
    resources:
        mem_mb=lambda wildcards, attempt: attempt * MEM
    params:
        taxdump=config['taxdump_path'],
        taxids=config['taxids'],
        outpath=config['extract_path'],
        descendants=config['descendants'],
        by_sample=config['by_sample']
    threads:
        config['threads']
    log:
        config['log_file']
    message:
        """Extracting query sequences from {input.fasta} for taxids: {params.taxids}
        Writing to {output}"""
    script: SCRIPT
