import pandas as pd
from mtsv.utils import (warn, info)
from string import Formatter
shell.prefix("set -euo pipefail;")

PATTERN = config.get('fastq_pattern', "reads/{sample}_R{pair}_001.fastq")
WILDCARDS = glob_wildcards(PATTERN)

SAMPLES = config.get('samples', list(set(WILDCARDS.sample)))


def get_wildcards_dataframe(wildcards):
    d = {k: getattr(wildcards, k) for k in wildcards._fields}
    return pd.DataFrame.from_dict(d)


WILDCARDS_DF = get_wildcards_dataframe(WILDCARDS)

def reformat_pattern(pattern):
    """
    Reformat wildcard file string to remove regex from key.
    """
    keys = [p[1]
            for p in Formatter().parse(pattern) if p[1] is not None]
    reformated_keys = [k.split(",")[0] for k in keys]
    for key, new_key in zip(keys, reformated_keys):
        pattern = pattern.replace(key, new_key)
    return pattern


def get_fastq_files(wildcards):
    sliced_wildcards = WILDCARDS_DF[
        WILDCARDS_DF['sample'] == wildcards.sample]
    return expand(
        reformat_pattern(PATTERN),
        zip, **{k: list(v.values) for k, v in
                sliced_wildcards.iteritems()})




rule fastp:
    """
    Run fastp quality control on input fastq reads.
    """
    input: get_fastq_files
    output:
        qc = "qc_reads/{sample}_qc.fastq",
        html = report(
            "qc_reads/{sample}_qc.html",
            caption="report/readprep_qc.rst",
            category="Readprep"),
        json = "qc_reads/{sample}_qc.json"
    log: "logs/{sample}_qc.log"
    threads: 1
    params:
        fastp_params = config.get(
            "fastp_params", "")
    message:
        """
        Running QC on fastqs: {input}.
        Writing to {output.qc} {output.html} {output.json}.
        Logging to {log}.
        Using {threads} threads.
        Additional parameters: {params}
        """
    run:
        # Multiple input files indicates paired reads
        # after processing the qc results will be written
        # interleaved to the same file.
        # try to decompress file if .gz extension
        import os
        input_files = []
        for fn in input:
            if os.path.splitext(fn)[-1] in [".gz", ".gzip"]:
                d_fn = os.path.splitext(fn)[0]
                input_files.append(d_fn)
                if not os.path.isfile(d_fn):
                    # only decompress if decompressed file is not present
                    shell("""
                    gzip -d -c {fn} > {d_fn}
                    """.format(fn=fn, d_fn=d_fn))
            else:
                input_files.append(fn)
        if len(input) > 1:
            shell("""
                fastp -i {input_files[0]} -I {input_files[1]} --stdout \
                --json {output.json} --html {output.html} \
                {params.fastp_params} > {output.qc} 2> {log}""")
        else:
            shell("""
            fastp -i {input_files[0]} -o {output.qc} \
            --json {output.json} --html {output.html} \
            {params.fastp_params} 2> {log}""")


rule readprep:
    """
    QC reads, generate and deduplicate query kmers.
    """
    input: "qc_reads/{sample}_qc.fastq"
    output: "queries/{sample}.fasta"
    log: "logs/{sample}_readprep.log"
    threads: 8
    params:
        kmer_size = config.get('kmer_size', 50)
    message:
        """
        Running Readprep on {input}.
        Writing to {output}.
        Logging to {log}.
        Using {threads} thread(s).
        Parameters: kmer_size={params.kmer_size}"""
    run:
        shell("""
            mtsv-readprep {input} -o {output} \
            --segment {params.kmer_size}  >> {log} 2>&1
            """)
