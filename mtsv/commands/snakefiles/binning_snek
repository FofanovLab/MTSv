import os
import json
import pandas as pd
import numpy as np
from Bio import SeqIO
from mtsv.parsing import (
    parse_query_id,
    format_cml_params,
    file_type, outfile_type,
    make_table)
from mtsv.utils import bin_path, track_file_params, get_database_params


shell.prefix("set -euo pipefail;")

BINS = {
    name: bin_path('mtsv-{}'.format(name))
    for name in [
        'binner','collapse']}

REPORT = outfile_type(os.path.join("Reports", "binning_report.html"))
config['fm_index_paths'] = [file_type(f) for f in get_database_params(
    config['database_config'], 'fm-index-paths')]


INDEX_PATH = [os.path.dirname(i) for i in config['fm_index_paths']]
INDEX = [os.path.basename(p).split(".")[0] for p in config['fm_index_paths']]
INDEX_DICT = {i: p for i, p in zip(INDEX, config['fm_index_paths'])}
INDEX_OUT = [
        os.path.join(
            config['binning_outpath'], "{}.bn".format(indx)) for indx in INDEX]
LOG = [os.path.join(config['binning_outpath'], "{}.log".format(indx))
        for indx in INDEX]

MODE_DICT = {'fast': {'seed_size': 17, 'min_seeds': 5, 'seed_gap': 2},
             'efficient': {'seed_size': 14, 'min_seeds': 4, 'seed_gap': 2},
             'sensitive': {'seed_size': 11, 'min_seeds': 3, 'seed_gap': 1}}

BIN_MODE = MODE_DICT[config['binning_mode']]
for key, value in BIN_MODE.items():
    if key not in config:
        # snakemake config does not allow dashes
        # but dashes are required for these mtsv params 
        config[key] = value
    config[key.replace("_", "-")] = value
    del config[key]

CML_PARAMS = format_cml_params(
    'BINNING',
    config,
    ['binning_mode', 'fm_index_paths', 'fasta', 'database_config',
    'merge_file', 'binning_outpath'],
    [])


rule binning_all:
    input: REPORT

rule binning_report:
    input:
        clps = config['merge_file'],
        fasta = config['fasta']
    output:
        rep=REPORT,
        unaligned = os.path.join(
            config['binning_outpath'],
            'unaligned_queries.fasta')
    message: 
        """
        Running binning report and finding unaligned queries.
        Writing report to {output.rep} 
        Writing unaligned queries to {output.unaligned}. 
        Snakemake sceduler assuming {threads} threads """ 
    # resources:
    #     mem_mb=lambda wildcards, input, attempt: max(1,
    #         attempt * int(
    #             os.path.getsize(input.clps) * 0.000001 + 
    #             os.path.getsize(input.fasta) * 0.000002))
    run:
        from snakemake.utils import report
        queries = SeqIO.to_dict(
            SeqIO.parse(input[1], "fasta"))
        hits = np.genfromtxt(
            input[0], delimiter=":", dtype=str, usecols=0)
        n_hits = len(hits)
        total_queries = len(queries)
        no_hits = np.setdiff1d(
            list(queries.keys()),
            hits,
            assume_unique=True)
        n_misses = len(no_hits)
        n_total_misses = np.array(np.sum(
            np.array(
                [parse_query_id(miss) for miss in no_hits],
                dtype=int), axis=0), dtype=str)

        n_total_hits = np.sum(
            np.array(
                [parse_query_id(hit) for hit in hits],
                dtype=int), axis=0)
        n_tot_hits = np.sum(n_total_hits)
        n_total_hits = np.array(n_total_hits, dtype=str)
        n_unique_hits = np.array(np.sum(
            np.array(
                [parse_query_id(hit) for hit in hits],
                dtype=bool), axis=0), dtype=str)


        header = json.loads(open(os.path.join(
            os.path.dirname(config['fasta']),
            ".params"),
            'r').read())['readprep'][config['fasta']]['fastq']
        header = [os.path.basename(h) for h in header]
        table = make_table(
            [header, n_total_misses, n_total_hits, n_unique_hits],
            ["Sample", "Total Unique Misses",
            "Total Hits", "Total Unique Hits"])
        no_hit_queries = [queries[query] for query in no_hits]
        with open(output['unaligned'], "w") as output_handle:
            SeqIO.write(no_hit_queries, output_handle, "fasta")
        
        track_file_params('merge_file', config['merge_file'], config)
        
        report("""
        Binning Report
        ================================
        Hits are reported in:\n
        {input.clps}\n
        There were **{n_tot_hits}** total hits and **{n_hits}** unique hits out 
        of **{total_queries}** unique queries.\n
        There were **{n_misses}** queries with no hits.\n
        These missed sequences are reported in {output.unaligned}.\n
        Total number of reads associated with misses by sample:\n
        {table}
        """, output['rep'])
            
rule binning:
    """Metagenomics binning"""
    output: os.path.join(config['binning_outpath'], "{index}.bn")
    input:
        reads = config['fasta'],
        fm_index = lambda wildcard: INDEX_DICT[wildcard.index]
        # fm_index = expand(
        #     "{path}/{index}.index", zip, path=INDEX_PATH, index=INDEX )
        # fm_index = os.path.join(INDEX_PATH, "{index}.index")
    # resources:
    #     mem_mb=lambda wildcards, attempt, input: max(1,
    #         int((os.path.getsize(input.reads) * 0.0000012 + 
    #         os.path.getsize(input.fm_index) * 0.0000011)) * 
    #         attempt)
    params:
        call=BINS['binner'],
        args=CML_PARAMS
    message:
        """
        Executing Binner on queries in {input.reads}.
        Using index {input.fm_index}
        Writing files to directory {output}
        Logging to {log}
        Snakemake sceduler assuming {threads} threads""" 
    log:
        os.path.join(config['binning_outpath'], "{index}.log")
    threads:
        config['threads']
    shell:
        """{params.call} --index {input.fm_index} --threads {threads} --results {output} --fasta {input.reads} {params.args} >> {log} 2>&1 """


rule collapse:
    """Combine the output of multiple separate mtsv runs. """
    output:
        config['merge_file']
    input:
        INDEX_OUT
    # resources:
    #     mem_mb=lambda wildcards, attempt, input: max(1,
    #         attempt * int(
    #             sum([os.path.getsize(i) for i in input]) * 0.0000012))
    message:
        """
        Merging binning output into {output}.
        Logging to {log}
        Snakemake sceduler assuming {threads} threads"""
    log:
        config['log_file']
    params:
        call=BINS['collapse']
    shell:
        """{params.call} {input} -o {output} >> {log} 2>&1"""



