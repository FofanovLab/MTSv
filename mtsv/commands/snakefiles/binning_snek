import os
import pandas as pd
import numpy as np
from Bio import SeqIO
from mtsv.parsing import parse_query_id, format_cml_params, file_type
from mtsv.utils import bin_path, track_file_params, get_database_params


shell.prefix("set -euo pipefail;")

BINS = {
    name: bin_path('mtsv-{}'.format(name))
    for name in [
        'binner','collapse']}

REPORT = "binning_report.html"
print(config)
config['fm_index_paths'] = [file_type(f) for f in get_database_params(
    config['database_config'], 'fm-index-paths')]
INDEX_PATH = os.path.dirname(config['fm_index_paths'][0])
INDEX = [os.path.basename(p).split(".")[0] for p in config['fm_index_paths']]
INDEX_OUT = [
        os.path.join(
            config['binning_outpath'], "{}.bn".format(indx)) for indx in INDEX]
LOG = [os.path.join(config['binning_outpath'], "{}.log".format(indx))
        for indx in INDEX]    

MODE_DICT = {'fast': {'seed_size': 17, 'min_seeds': 5, 'seed_gap': 2},
             'efficient': {'seed_size': 14, 'min_seeds': 4, 'seed_gap': 2},
             'sensitive': {'seed_size': 11, 'min_seeds': 3, 'seed_gap': 1}}

BIN_MODE = MODE_DICT[config['binning_mode']]
for key, value in BIN_MODE.items():
    if key not in config:
        # snakemake config does not allow dashes
        # but dashes are required for these mtsv params 
        config[key.replace("_", "-")] = value
        del config[key]


CML_PARAMS = format_cml_params(
    'BINNING',
    config,
    ['binning_mode', 'fm_index_paths', 'fasta', 'database_config',
    'merge_file', 'binning_outpath'],
    [])
    
MEM=50

rule binning_all:
    input: REPORT

rule binning_report:
    input:
        clps = config['merge_file'],
        fasta = config['fasta']
    output:
        rep=REPORT,
        unaligned = os.path.join(
            config['binning_outpath'],
            'unaligned_queries.fasta')
    run:
        from snakemake.utils import report
        queries = SeqIO.to_dict(
            SeqIO.parse(input['fasta'], "fasta"))
        hits = np.loadtxt(
            input['clps'], delimiter=":", dtype=str, usecols=0)
        n_hits = len(hits)
        total_queries = len(queries)
        no_hits = np.setdiff1d(
            list(queries.keys()),
            hits,
            assume_unique=True)
        n_misses = len(no_hits)
        n_total_misses = "\t".join(np.array(np.sum(
            np.array(
                [parse_query_id(miss) for miss in no_hits],
                dtype=int), axis=0), dtype=str))
        
        no_hit_queries = [queries[query] for query in no_hits]
        with open(output['unaligned'], "w") as output_handle:
            SeqIO.write(no_hit_queries, output_handle, "fasta")
        
        track_file_params('merge_file', config['merge_file'], config)
        
        report("""
        Binning Report
        ================================
        Hits are reported in:\n
        {input.clps}\n
        There were **{n_hits}** unique hits out 
        of **{total_queries}** unique queries.\n
        There were **{n_misses}** queries with no hits.\n
        These missed sequences are reported in Misses_.\n
        Total number of reads associated with misses by sample:\n
        **{n_total_misses}**
        """, output['rep'], Misses=output['unaligned'])
            
rule binning:
    """Metagenomics binning"""
    output:
        os.path.join(config['binning_outpath'], "{index}.bn")
    input:
        reads = config['fasta'],
        fm_index = os.path.join(INDEX_PATH, "{index}.index")
    resources:
        mem_mb=lambda wildcards, attempt: attempt * MEM
    params:
        call=BINS['binner'],
        args=CML_PARAMS
    message:
        "Executing Binner with {threads} threads on the following files {input}."
    log:
        os.path.join(config['binning_outpath'], "{index}.log")
    threads:
        config['threads']
    shell:
        """{params.call} --index {input.fm_index} --threads {threads} --results {output} --fasta {input.reads} {params.args} >> {log} 2>&1 """


rule collapse:
    """Combine the output of multiple separate mtsv runs. """
    output:
        config['merge_file']
    input:
        INDEX_OUT
    resources:
        mem_mb=lambda wildcards, attempt: attempt * MEM
    message:
        "Merging binning output files into {output}."
    log:
        config['log_file']
    params:
        call=BINS['collapse']
    shell:
        """{params.call} {input} -o {output} >> {log} 2>&1"""
