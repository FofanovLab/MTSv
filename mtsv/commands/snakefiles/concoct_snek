

def get_threshold(config):
    """
    Parse threshold value to name output files.
    """     
    concoct_opts = [
        p.strip() for p in
            config.get("concoct_params", "-l 1000").split(" ")]
    threshold_flag = list(
        set(["-l", "--length_threshold"]).intersection(set(concoct_opts)))
    if threshold_flag:
        idx = min([concoct_opts.index(c) for c in threshold_flag]) # get first
    # remove the flag and value from options, set threshold to the value
        threshold = [concoct_opts.pop(idx), concoct_opts.pop(idx)][-1]
    else:
        threshold = "1000"     
    return (threshold, " ".join(concoct_opts))


THRESHOLD, CONCOCT_OPTS = get_threshold(config)
        
rule megahit:
    """
    Metagenomic assembly using megahit.
    """
    input: "unaligned_queries/{sample}_unaligned.fasta"
    output: "alignment_free_binning/megahit_{sample}/final.contigs.fa"
    params: config.get("megahit_params", "")
    log: "logs/{sample}_megahit.log"
    threads: 12
    message:
        """
        Getting metagenomic assembly (megahit) from unaligned queries {input}.
        Writing to {output}.
        Additional Params: {params}
        Logging to {log}.
        Using {threads} thread(s).
        """
    shell:
        """
        echo MEGAHIT {wildcards.sample} >> {log}
        rm -rf alignment_free_binning/megahit_{wildcards.sample}
        megahit -r {input} -o alignment_free_binning/megahit_{wildcards.sample} \
            -t {threads} {params} >> {log} 2>&1 
        echo END MEGAHIT {wildcards.sample} >> {log}
        """

rule concoct_cut_up:
    """
    Cut assembled contigs into smaller sequences.
    """
    input: "alignment_free_binning/megahit_{sample}/final.contigs.fa"
    output:
        bed = "alignment_free_binning/concoct_{sample}/{sample}.bed",
        cut = "alignment_free_binning/concoct_{sample}/{sample}_cut.fasta"
    params: config.get("cutup_params", "")
    threads: 1
    message:
        """
        Cutting assembled contings into smaller parts using {input}.
        Writing to {output.bed} and {output.cut}.
        Additional Params: {params}
        Using {threads} thread(s).
        """
    shell:
        """
        mkdir -p alignment_free_binning/concoct_{wildcards.sample};
        cut_up_fasta.py {input} -b {output.bed} {params} > {output.cut}
        """


rule concoct_fasta2fastq:
    """
    Covert unaligned fasta queries to a fastq. 
    """
    input: "unaligned_queries/{sample}_unaligned.fasta"
    output: "alignment_free_binning/concoct_{sample}/unaligned_queries_{sample}.fastq"
    threads: 1
    message:
        """
        Converting unaligned fasta queries {input}
        to fastq {output}.
        Using {threads} thread(s).
        """
    run:
        from Bio import SeqIO
        with open(input[0], 'r') as handle:
            with open(output[0], 'w') as out:
                for record in SeqIO.parse(handle, 'fasta'):
                    record.letter_annotations["phred_quality"] = (
                        [40] * len(record))
                    name = record.id
                    for rep in range(int(record.id.split("_")[-1])):
                        SeqIO.write(record, out, "fastq")


rule concoct_make_bam:
    """
    Generate a bam file by mapping queries back to the contigs.
    """
    input:
        ref = "alignment_free_binning/megahit_{sample}/final.contigs.fa",
        fastq = "alignment_free_binning/concoct_{sample}/unaligned_queries_{sample}.fastq"
    output: 
        bam = "alignment_free_binning/concoct_{sample}/{sample}.bam",
        bai = "alignment_free_binning/concoct_{sample}/{sample}.bam.bai"
    params: config.get("bwa_params", "")
    log: "logs/concoct_{sample}_bam.log"
    threads: 12
    message:
        """
        Mapping reads (BWA MEM) and indexing (Samtools) 
        bam file using from reference {input.ref} 
        and reads {input.fastq}.
        Writing to {output.bam} and {output.bai}.
        Additional Params: {params}
        Logging to {log}.
        Using {threads} thread(s).
        """
    shell:
        """
        echo MAKE BAM {wildcards.sample} >> {log}
        if [[ -s {input.ref} ]]
        then
            bwa index {input.ref} &>> {log}
            bwa mem -t {threads} {params} {input.ref} {input.fastq} 2>> {log} | \
            samtools view -uS | samtools sort -@ {threads} -o {output.bam} &>> {log}
            samtools index {output.bam} &>> {log}
        else
            touch {output.bam} {output.bai}
            echo "NO ASSEMBLY: DETECTED" >> {log}
        fi
        echo END MAKE BAM {wildcards.sample} >> {log}
        """

rule concoct_coverage_table:
    """
    Generate table with coverage depth information.
    """
    input:
        bed = "alignment_free_binning/concoct_{sample}/{sample}.bed",
        bai = "alignment_free_binning/concoct_{sample}/{sample}.bam.bai",
        bam = "alignment_free_binning/concoct_{sample}/{sample}.bam"
    output: "alignment_free_binning/concoct_{sample}/{sample}_coverage_table.tsv"
    log: "logs/concoct_{sample}_coverage_table.log"
    threads: 1
    message:
        """
        Generating coverage table using {input.bed}, {input.bai} and {input.bam}.
        Writing to {output}.
        Logging to {log}.
        Using {threads} thread(s).
        """ 
    shell:
        """
        echo COVERAGE_TABLE {wildcards.sample} >> {log}
        if [[ -s {input.bam} ]]
        then
            concoct_coverage_table.py {input.bed} {input.bam} > {output}
        else
            touch {output}
            echo "SKIPPING COVERAGE" >> {log}
        fi
        echo END COVERAGE_TABLE {wildcards.sample} >> {log}
        """



rule concoct:
    """
    Run concoct alignment-free binning.
    """
    input:
        cov="alignment_free_binning/concoct_{sample}/{sample}_coverage_table.tsv",
        cut = "alignment_free_binning/concoct_{sample}/{sample}_cut.fasta"
    output: 
        expand(
            "alignment_free_binning/concoct_{{sample}}/clustering_gt{param}.csv",
            param=THRESHOLD)
    params:
        threshold=THRESHOLD,
        opts=CONCOCT_OPTS
    log: "logs/{sample}_concoct.log"
    threads: 12
    message:
        """
        Running concoct using coverage table {input.cov} and fasta {input.cut}.
        Writing to {output}.
        Additional Params: length_threshold={params.threshold} {params.opts} 
        Logging to {log}.
        Using {threads} thread(s).
        """
    shell:
        """
        echo CONCOCT {wildcards.sample} >> {log}
        if [[ -s {input.cov} ]]
        then
            concoct -l {params.threshold} -t {threads} --composition_file {input.cut} \
            --coverage_file {input.cov} \
            -b alignment_free_binning/concoct_{wildcards.sample}/ \
            {params.opts} &>> {log}
        else
            touch {output}
            echo "SKIPPING CONCOCT" >> {log}
        fi
        echo END CONCOCT {wildcards.sample} >> {log}
        """



rule concoct_merge:
    """
    Merge subcontig clustering into original contig clustering.
    """
    input: 
        expand(
            "alignment_free_binning/concoct_{{sample}}/clustering_gt{param}.csv",
            param=THRESHOLD)
    output: "alignment_free_binning/concoct_{sample}/clustering_merged.csv"
    threads: 1
    log: "logs/concoct_{sample}_merge_clusters.log"
    message:
        """
        Merge clustering from {input}.
        Writing to {output}.
        Logging to {log}.
        Using {threads} thread(s).
        """
    shell:
        """
        echo MERGE CLUSTERS {wildcards.sample} >> {log}
        merge_cutup_clustering.py {input} > {output} 2>> {log}
        echo END MERGE CLUSTERS {wildcards.sample} >> {log}
        """

rule concoct_fasta_bins:
    """
    Extract bins as individual fastas.
    """
    input: 
        clustered = "alignment_free_binning/concoct_{sample}/clustering_merged.csv",
        assembly = "alignment_free_binning/megahit_{sample}/final.contigs.fa"
    output: 
        touch("alignment_free_binning/concoct_{sample}/{sample}.done")
    params:
        outpath = "alignment_free_binning/concoct_{sample}/fasta_bins"
    log: "logs/concoct_{sample}_bin_fastas.log"
    threads: 1
    message:
        """
        Extracting bins into individual fasta files.
        Using cluster file {input.clustered} and assemblies {input.assembly}.
        Writing to {params.outpath}.
        Logging to {log}.
        Using {threads} thread(s).
        """
    shell:
        """
        echo FASTA_BINS {wildcards.sample} >> {log}
        mkdir -p {params.outpath}
        if [[ -s {input.clustered} ]]
        then
            extract_fasta_bins.py {input.assembly} {input.clustered} --output_path {params.outpath} &>> {log}
        else
            touch {output}
            echo CLUSTER FILE IS EMPTY: SKIPPING EXTRACTION >> {log}
        fi
        echo END FASTA_BINS {wildcards.sample} >> {log}
        """






